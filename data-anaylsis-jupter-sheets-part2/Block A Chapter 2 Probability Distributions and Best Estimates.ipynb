{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is some code to get pretty highlighted cells for the questions - ignore this\n",
    "from IPython.display import HTML\n",
    "style1 = \"<style>div.warn { background-color: #fcf2f2;border-color: #dFb5b4; border-left: 5px solid #dfb5b4; padding: 0.5em;}</style>\"\n",
    "HTML(style1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers some worked examples and some examples for you to try relating to **Block A, Chapter 2** in the notes.  This is practice and core material for coursework 1. The green questions are those most closely related to the assessed work for this module. *Once you have completed this notebook, you will be able to attempt QNs 2 and 3 on coursework 1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The BEST estimate (mean, standard deviation, variance and median)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we are trying to measure the length of a snake, where length is defined as x.  The snake keeps moving around so we know we will have some errors in our measurements.  We decide to take *10 measurements* and we measure the length x to be:\n",
    "\n",
    "26, 24, 26, 28, 23, 24, 25, 24, 26, 25\n",
    "\n",
    "The best way to estimate the length would be to simply take the *mean*.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{x} =  \\dfrac{\\sum^N_i x_i}{N}\n",
    "\\end{equation*}\n",
    "\n",
    "where N is the number of measurements.\n",
    "\n",
    "What about an error on our mean?  We can do this by asking what is the difference between each value we measure and our mean value eg $d = x_i - \\hat{x}$?  But we have 10 of these estimates and we only want one number for our error, so we need to sum these values and divide by $N$. *However* this does not account for the fact that $d$ can be positive or negative, so what we really want is a value of the absolute difference between the mean and our individual measurements. To do this we need to square our differences.  The error then is the well known standard deviation $\\sigma_x$\n",
    "\n",
    "$\\sigma_x =  \\sqrt{ \\dfrac{\\sum^N_i (x_i - \\hat{x})^2}{N} }$\n",
    "\n",
    "except that we need to take into account the number of degrees of freedom. This is because we've had to use the data to estimate our mean $\\hat{x}$ in order to calculate the *sample* standard deviation so it is in fact:\n",
    "\n",
    "$\\sigma_x =  \\sqrt{ \\dfrac{\\sum^N_i (x_i - \\hat{x})^2}{N-1}} $\n",
    "\n",
    "Or we can cheat a little and use inbuilt stat functions from numpy and scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "x = [26,24,26,28,23,24,25,24,26,25]\n",
    "n=len(x)\n",
    "\n",
    "mean = np.mean(x) \n",
    "\n",
    "standard_dev = np.std(x)  # standard deviation function in numpy\n",
    "\n",
    "standard_error = stats.sem(x)  # standard error on the mean function in scipy.stats\n",
    "\n",
    "standard_dev_samp = np.sqrt( np.sum((x-mean)**2.0)/(n-1)) # standard deviation sample N-1\n",
    "\n",
    "\n",
    "print('mean = {:.2f} '.format(mean))\n",
    "print('standard deviation = {:.2f}'.format(standard_dev) )\n",
    "print('error on mean = {:.2f}'.format(standard_error))\n",
    "print('sample standard deviation = {:.2f}'.format(standard_dev_samp) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's now take a look at our distribution of data for the length of the snake.  Let's take each *different* measured length to be $x_k$ and look at how many times that value was measured.\n",
    "\n",
    "|Measured length of snake|23|24|25|26|27|28|\n",
    "|----|---|\n",
    "|Frequency of how many times that length is measured|1|3|2|3|0|1|\n",
    "\n",
    "If we were to plot this as a bar graph, this would be the histogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make a plot we need to import plotting package\n",
    "from pylab import plt\n",
    "# this makes the plot appear in the notebook\n",
    "% matplotlib inline\n",
    "\n",
    "# length of snake measurements\n",
    "x = [26,24,26,28,23,24,25,24,26,25]\n",
    "\n",
    "# plot the histogram\n",
    "plt.hist(x,bins=8,histtype='bar')\n",
    "plt.ylabel('frequency')\n",
    "plt.xlabel('length of snake x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean in this case would be \n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{x} = {\\sum_k x_k n_k \\over {N}}\n",
    "\\end{equation*}\n",
    "\n",
    "where $n_k$ is the number of instances that that the measurement $x_k$ was made.  Note that $\\sum n_k = N$. \n",
    "\n",
    "We can look at this another way, each result $x_k$ occurs a certain fraction of times $F_k$ where, out of 10 measurements, we measured a value of 24 three times ie $F_k = n_k/N$.  The mean would then be \n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{x} = {\\sum_k x_k F_k}\n",
    "\\end{equation*}\n",
    "\n",
    "and $\\sum_k F_k = 1$.\n",
    "\n",
    "What if our measurements were not exactly 23 and 24, but were instead 23.6 and 24.3? Our new, more precise, measurements of the length of the snake are \n",
    "\n",
    "26.4, 23.9, 25.1, 24.6, 22.7, 23.8, 25.1, 23.9, 25.3, 25.4. \n",
    "\n",
    "So we now need to think of distributing them in the following way \n",
    "\n",
    "|Bin|22 to 23|23 to 24|24 to 25|25 to 26|26 to 27|27 to 28|\n",
    "|----|---|\n",
    "|Frequency of how many times that length is measured|1|3|1|4|1|0|\n",
    "\n",
    "where the bin width is denoted as $\\Delta_k$, and the area of the bin represents the fraction of measurements that fall within the $k$th bin ie $f_k\\Delta_k$.  \n",
    "\n",
    "Now we can start talking about what happens as our number of measurements approaches infinity $N \\to \\infty$. Two things will happen. 1) the distribution (our histogram) is said to approach the *limiting distribution* and 2) $f_k \\to f(x)$ and $\\Delta_k \\to dx$ so that, whereas before we had $\\sum f_k ~ \\Delta_k = 1$ for all $k$, now we have\n",
    "\n",
    "\\begin{equation*}\n",
    "\\int^{\\infty}_{-\\infty} f(x)~ dx = 1\n",
    "\\end{equation*}\n",
    "\n",
    "and so the histrogram approaches the *probability density function* (PDF) of the limiting distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make a plot we need to import plotting package\n",
    "from pylab import plt\n",
    "# this makes the plot appear in the notebook\n",
    "% matplotlib inline\n",
    "\n",
    "# length of snake measurements\n",
    "x = [26.4,23.9,25.1,24.6,22.7,23.8,25.1,23.9,25.3,25.4]\n",
    "\n",
    "# get the histogram counts (frequency) and the bin edges from python\n",
    "hist, bin_edges = np.histogram(x, normed=True)\n",
    "# need to work out size of bins as we want to plot freq x bin width on y axis\n",
    "binWidth = bin_edges[1] - bin_edges[0]\n",
    "\n",
    "# plot\n",
    "plt.bar(bin_edges[:-1], hist*binWidth, binWidth)\n",
    "plt.ylabel('$f_k \\Delta k$')\n",
    "plt.xlabel('length of snake x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now introduce the formal definition of the mean as $N \\to \\infty$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\hat{x} = \\sum_k x_k ~ F_k = \\sum_k x_k~ f_k ~\\Delta_k \\to \\int^{\\infty}_ {-\\infty} x ~f(x)~ dx \n",
    "\\end{equation*}\n",
    "\n",
    "and similarly for the standard deviation: \n",
    "\n",
    "\\begin{equation*}\n",
    "\\sigma_x = \\sqrt{  \\int^{\\infty}_ {-\\infty} (x-\\hat{x})^2 ~f(x)~ dx   }\n",
    "\\end{equation*}\n",
    "\n",
    "where we don't need to worry about $N$ or $N-1$ in the denominators as we're in the regime where $N \\to \\infty$. \n",
    "\n",
    "Because we now have this terminology, we can also define the *cumulant* distribution where\n",
    "\n",
    "\\begin{equation*}\n",
    "F(x') = \\int^{x'}_ {-\\infty} f(x)~ dx \n",
    "\\end{equation*}\n",
    "\n",
    "where $F(x')$ tells us the percentile that $x'$ represents, eg if $F(x')=0.6$ then 0.6 or 60% of the area under the function $f(x)$ would lie in the range $\\le x'$. Note that the lower limit could be any bound over which the distribution is valid.\n",
    "\n",
    "The *median* is the special case where $F(x) = 0.5$ - the 50th percentile. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been introduced to the idea that histograms are an approximation to the underlying limiting distribution and that experimental results sample from the limiting distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bias** \n",
    "\n",
    "In statistics, the bias (or bias function) of an estimator is the difference between this estimator's expected value $E(x)$ and the true value of the parameter being estimated. An estimator or decision rule with zero bias is called unbiased.  Or we can write this another way: an estimator is said to be unbiased, if the estimator tends towards the expected value as the sample size (i.e. the number of values / measurements) tends towards infinity.\n",
    "\n",
    "The mean is an unbiased estimator of $E(x)$, since as the number of points increases, the mean tends towards $E(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum likelihood** is the idea is that the best guess for the values of $x_0$ and $\\sigma$ are those that maximise the probability. Given $N$ observed measurements $x_1,...,x_N$, the best estimates for the mean and standard deviation are those values for which the observed $x_1,...,x_N$ are most likely, or rather where $p_{\\hat{x},\\sigma}(x_1,...,x_N)$ is the maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The Normal Distribution**\n",
    "\n",
    "The form of the normal distribution with width $\\sigma$, for data value $x$ centred on a value of $x$ given by $x_0$\n",
    "\n",
    "$N_{x_0, \\sigma}(x) = \\dfrac{1}{\\sigma\\sqrt{2\\pi}} e^{-(x-x_0)^2/2\\sigma^2}.$\n",
    "\n",
    "We can show that the mean of the normal distribution is simply \n",
    "\n",
    "$\\hat{x} = x_0$\n",
    "\n",
    "and the standard deviation of the data that follow a normal distribution is\n",
    "\n",
    "$\\sigma_x = \\sigma$.\n",
    "\n",
    "How did we get this?\n",
    "\n",
    "We first have to normalise the function to use it as a probability, such that it satisfies,\n",
    "\n",
    "$\\int_{-\\infty}^{\\infty} N(x) dx = 1$ \n",
    "\n",
    "We introduce a constant $C$, such that,\n",
    "\n",
    "$N(x) = C\\, e^{-(x-x_0)^2/2\\sigma^2}.$\n",
    "\n",
    "Note that $C$ only serves to the move the curve up an down in $y$, but leaves the shape and centring undisturbed; it obviously changes the area under the curve though, which is the whole point in the normalisation. To evaluate the integral, we make a change of variable, by setting $(x - x_0)/\\sigma = z$, such that $dx = \\sigma dz$ to get,\n",
    "\n",
    "$\\int_{-\\infty}^{\\infty} N(z) dz = C\\sigma\\, \\int_{-\\infty}^{\\infty} e^{-z^2/2} dz$\n",
    "\n",
    "This is a standard integral in physics, and has the result,\n",
    "\n",
    "$\\int_{-\\infty}^{\\infty} e^{-z^2/2} dz = \\sqrt{2\\pi},$\n",
    "\n",
    "which yields the value for the normalisation $C = 1/ \\sigma\\sqrt{2\\pi}$. We can then write the final form for the normal distribution as,\n",
    "\n",
    "$N_{x_0, \\sigma}(x) = \\dfrac{1}{\\sigma\\sqrt{2\\pi}} e^{-(x-x_0)^2/2\\sigma^2}$\n",
    "\n",
    "The know that the mean of a PDF is \n",
    "\n",
    "$\\hat x = \\int_{-\\infty}^{\\infty} x\\,N_{x_0, \\sigma}(x) dx =  \\dfrac{1}{\\sigma\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} x\\, e^{-(x-x_0)^2/2\\sigma^2} dx.$\n",
    "\n",
    "Again, this can be evaluated with a change of variables, replacing $x - x_0 = y$, such that $dx = dy$ and $x = y + x_0$. This results in,\n",
    "\n",
    "$\\hat x =  \\dfrac{1}{\\sigma\\sqrt{2\\pi}} \\left( \\int_{-\\infty}^{\\infty} y \\,e^{-y^2/2\\sigma^2} dy ~ + ~ x_0 \\int_{-\\infty}^{\\infty} e^{-y^2/2\\sigma^2} dy    \\right).$\n",
    "\n",
    "The first integral is zero, since although the exponential term is symmetric about $y = 0$, the $y$ is not, and so the points from $-y$ are exactly cancelled by those from $+y$. The second integral is the same as that we seen above, and is just $\\sigma \\sqrt{2\\pi}$, which cancels with the term at the front, leaving us with,\n",
    "\n",
    "$\\hat x = x_0$.\n",
    "\n",
    "Similarly for the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the measurement of a particular quantity is subject to many, independent and random errors, then the *central limit theorem* allows us to use the normal distribution to model the quantity’s errors.\n",
    "\n",
    "\n",
    "Note that there are two types of errors:\n",
    "*statistical errors* - from random nature of measurement process, can be reduced by increasing the number of measurements and averaging over them.\n",
    "*systematic errors* - these arise from flawed measurements (eg voltmeter adding +2V to every measurement because its not properly calibrated). This is easy to spot as it remains even after repeating measurements multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Probabilities from Normal distributions**\n",
    "\n",
    "Since $N_{x_0, \\sigma}(x)$ is a PDF, the probability of $x$ lying in the range $a$ to $b$ is then given by,\n",
    "\n",
    "$\\int_a^b  N_{x_0, \\sigma}(x) dx.$\n",
    "\n",
    "So what about the probability of lying within $\\pm t \\sigma$ eg 1, 2 or 3$\\sigma$, where $t$ is some real (positive) number? This is given by,\n",
    "\n",
    "$P(\\rm{within} ~t \\sigma) = \\dfrac{1}{\\sigma \\sqrt{2\\pi}} \\int_{x_0 - t\\sigma}^{x_0 + t\\sigma} e^{-(x - x_0)^2/2\\sigma^2} dx.$\n",
    "\n",
    "Once again, substitution of $(x-x_0)/\\sigma = z$, with $dx = \\sigma dz$ and now limits of $-t$ to $t$, we have,\n",
    "\n",
    "$P(\\rm{within} ~t \\sigma) = \\dfrac{1}{\\sqrt{2\\pi}} \\int_{-t}^{+t} e^{-z^2/2} dz.$\n",
    "\n",
    "The equation above is known as the *error function*.  Unfortunately, it can not be evaluated analytically, however using a computer, it is possible to obtain values for the integral as a function of $t$, and we can use reference tables to look this up.  The probability that a measurement lies within $1\\sigma$ of the mean is 68%. \n",
    "\n",
    "\\Pr(\\mu -1\\sigma \\leq X\\leq \\mu +1\\sigma )&\\approx 0.6827\\\\\\Pr(\\mu -2\\sigma \\leq X\\leq \\mu +2\\sigma )&\\approx 0.9545\\\\\\Pr(\\mu -3\\sigma \\leq X\\leq \\mu +3\\sigma )&\\approx 0.9973\\end{aligned}}}\n",
    "\n",
    "$P(\\mu -1\\sigma < X < \\mu + 1\\sigma) \\sim 0.6827$ \n",
    "\n",
    "$P(\\mu -2\\sigma < X < \\mu + 2\\sigma) \\sim 0.9545$\n",
    "\n",
    "$P(\\mu -3\\sigma < X < \\mu + 3\\sigma) \\sim 0.9973$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORKED EXAMPLE:\n",
    "\n",
    "At a facility that manufactures electrical resistors, a statistical sample of 1 k$\\Omega$ resistors is pulled from the production line. The resistor's resistances are measured and recorded. A mean resistance of 979.8 k$\\Omega$ and a standard deviation of 73.10 k$\\Omega$ represents the sample of resistors. The desired resistance tolerance for the 1-k$\\Omega$ resistors is $\\pm$ 10%. This tolerance range means the acceptable range of resistance is 900 to 1100 $\\Omega$. \n",
    "\n",
    "Assuming a normal distribution, show the probability that a resistor picked off the production line is within the desired tolerance on a plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "As we are interested in the probability, we use the equation above\n",
    "\n",
    "$P(\\rm{within} ~t \\sigma) = \\dfrac{1}{\\sqrt{2\\pi}} \\int_{-t}^{+t} e^{-z^2/2} dz.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "# install packaged to do a normal function\n",
    "from scipy.stats import norm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# define constants\n",
    "mu = 998.8 \n",
    "sigma = 73.10\n",
    "\n",
    "# acceptable values of resistance\n",
    "x1 = 900\n",
    "x2 = 1100\n",
    "\n",
    "# calculate the z-transform x - x_o /sigma\n",
    "# this will move x axis to +/- sigmas rather than resistance\n",
    "z1 = ( x1 - mu ) / sigma\n",
    "z2 = ( x2 - mu ) / sigma\n",
    "\n",
    "# range of x in spec \n",
    "x = np.arange(z1, z2, 0.001) \n",
    "\n",
    "# plot distribution for +/1 10 sigma as comparison\n",
    "x_all = np.arange(-10, 10, 0.001) \n",
    "\n",
    "# mean = 0, stddev = 1, since Z-transform was calculated\n",
    "y = norm.pdf(x,0,1)\n",
    "y2 = norm.pdf(x_all,0,1)\n",
    "\n",
    "# build the plot\n",
    "plt.plot(x_all,y2)\n",
    "\n",
    "# this shows dark shaded region for acceptable values of resistor\n",
    "plt.fill_between(x,y,0, alpha=0.3, color='b') \n",
    "# this gills in the gap between the PDF and the accepted values\n",
    "plt.fill_between(x_all,y2,0, alpha=0.1)\n",
    "plt.xlim([-4,4])\n",
    "plt.xlabel('# of Standard Deviations Outside the Mean')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the area corresponding to resistors in the given specification (between the upper and lower bounds) is shaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bernoulli Distribution**\n",
    "\n",
    "A Bernoulli event is one in which the outcomes are of the yes/no variety, such as, did the coin land heads?, did the patient survive 3 years after treatment? \n",
    "\n",
    "If our probability of success in one trial is represented by $\\theta$, we can then write the probability of success in $p$ given $\\theta$ as,\n",
    "\n",
    "$p(x|\\theta) = \\theta^x(1 − \\theta)^{(1−x)}$.\n",
    "\n",
    "where $x= 0$ for failure, or $1$ for success. Eg for rolling a six with a fair dice, $x=1$ for rolling a 6, and 0 for anything else. In this case the probability for rolling a six in one trial $\\theta$ would be 1/6.\n",
    "\n",
    "We can write the probability of obtaining any particular sequence of successes for $\\nu =$ number of successes \n",
    "\n",
    "$p(\\nu|N, \\theta) = \\theta^{\\nu} (1 − \\theta)^{(N−\\nu)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The Binomial Distribution** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binomial distribution is a discrete probability distribution like Bernoulli. It can be used to obtain the number of successes from N Bernoulli trials.\n",
    "\n",
    "Let's consider rolling 3 dice at the same time. What is the probability of getting $\\nu$ sixes, where now $\\nu = \\{0, 1, 2, 3\\}$?  First, consider $\\nu = 0$,\n",
    "\n",
    "$p(\\rm{not~ 6, not ~6, not~ 6}) = \\left( \\dfrac{5} {6} \\right)^3$\n",
    "and then consider $\\nu = 3$,\n",
    "\n",
    "$p(\\rm{6, ~6,~ 6}) = \\left( \\dfrac{1} {6} \\right)^3.$\n",
    "\n",
    "These were the most straightforward as there is only 1 way in which they can occur. But now let's consider ($\\nu = 1$). This can occur in 3 ways:\n",
    "\n",
    "\\begin{align}\n",
    "p(\\rm{one ~6 ~in~ 3}) & =  p(\\rm{6, not ~6, not ~6}) +  p(\\rm{not~ 6, 6, not ~6}) + p(\\rm{not ~6, not~ 6,~ 6}) \\\\\n",
    "                                      & =  3 \\left( \\dfrac{1} {6} \\right) \\left( \\dfrac{5} {6} \\right)^2.\n",
    "\\end{align}\n",
    "\n",
    "Similarly for $\\nu = 2$:\n",
    "\n",
    "\\begin{align}\n",
    "p(\\text{two 6 in 3}) & =  p(\\text{6, 6, not 6}) +  p(\\text{6, not 6,  6}) + p(\\text{not 6, 6, 6}) \\\\\n",
    "                                      & =  3 \\left( \\dfrac{1} {6} \\right)^2 \\left( \\dfrac{5} {6} \\right).\n",
    "\\end{align}\n",
    "\n",
    "The coefficients that sit in front of the $\\theta$ and $\\theta -1$ terms are given by the Binomial Coefficient,\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "{N \\choose \\nu} & = \\dfrac{N(N-1) \\dotsb (N - \\nu + 1)}  {1 \\times 2 \\times \\dotsb  \\times \\nu} \\\\\n",
    "                                      & = \\dfrac{N!} {\\nu!(N - \\nu)!}\n",
    "\\end{align}\n",
    "\n",
    "The *Binomial Distribution* is therefore,\n",
    "\n",
    "\n",
    "$B_{N, \\theta} (\\nu) = {N \\choose \\nu} \\theta^\\nu (1 - \\theta)^{(N - \\nu)}.$\n",
    "\n",
    "The mean of the Binomial Distribution are given by,\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\nu} & = \\sum \\nu B_{N, \\theta} (\\nu) \\\\\n",
    "& = N \\theta,\n",
    "\\end{align}\n",
    "\n",
    "that is, if you repeat the experiment $N$ times, the average number of successes is simply the probability of success in any one trail times the number of trials. The standard deviation is little trickier to evaluate, but is given by,\n",
    "\n",
    "$\\sigma_{\\nu} = \\sqrt{N\\theta(1 - \\theta)}.$\n",
    "\n",
    "You can get access to python's inbuilt binomial calculator by using `scipy.stats`.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worked example:\n",
    "\n",
    "Suppose a dice is tossed 5 times. What is the probability of getting exactly 2 fours?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "This is a binomial experiment in which the number of trials is equal to 5, the number of successes is equal to 2, and the probability of success on a single trial is 1/6.  The binomial distribution is given by\n",
    "\n",
    "$B_{N, \\theta} (\\nu) = {N \\choose \\nu} \\theta^\\nu (1 - \\theta)^{(N - \\nu)}.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "# set up values\n",
    "N=5\n",
    "nu = 2\n",
    "\n",
    "# prob of single trial\n",
    "theta = 1./6\n",
    "\n",
    "prob = binom.pmf(nu,N, theta)\n",
    "\n",
    "print('probability of getting exactly 2 fours is {:.2f}'.format(prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the binomial distribution look like if the probability of success in $N=17$ trials is $\\theta = 0.7$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# generate some x values to plot the binomial function\n",
    "x = np.arange(0,30)\n",
    "\n",
    "n =17\n",
    "theta = 0.7\n",
    "\n",
    "mean_bi = n*theta\n",
    "err_bi = np.sqrt(n*theta*(1-theta))\n",
    "\n",
    "print('the mean and standard deviation are {:.2f} +/- {:.2f}'.format(mean_bi,err_bi))\n",
    "\n",
    "data=binom.pmf(x,n,theta)\n",
    "plt.plot(x,data)\n",
    "plt.xlabel('number of successes')\n",
    "plt.ylabel('probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beta Distributions**\n",
    "\n",
    "The functional family that has the same form as Bernoulli and Binomial distributions are called *beta distributions*. The probability density function are (usually) denoted  by,\n",
    "\n",
    "$p(\\theta | ~a, b) = \\rm{beta}(\\theta | a, b) =  \\dfrac{ \\theta^{(a - 1)} (1 - \\theta)^{(b - 1)} }{B(a, b)}$\n",
    "\n",
    "where $a$ and $b$ are shape paramaters and $B(a, b)$ is the normalisation factor that ensures that the area under the curve integrates to unity,\n",
    "\n",
    "$B(a, b) = \\int_0^1 \\theta^{(a - 1)} (1 - \\theta)^{(b - 1)} d\\theta.$\n",
    "\n",
    "The mean and variance of the beta distribution are given by,\n",
    "\n",
    "$\\hat{\\theta}_{B} = \\dfrac{a}{a+b}$\n",
    "\n",
    "$\\sigma_{\\sigma}^2  = \\dfrac{ \\hat{\\theta}(1 - \\hat{\\theta})}  {a + b + 1}.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot some beta distributions\n",
    "# import the distribution and do it the easy way:\n",
    "from scipy.stats import beta\n",
    "\n",
    "# let's do it for 4 different parameters\n",
    "\n",
    "a = [0.5, 1.5, 3.0, 0.5]\n",
    "b = [0.5, 1.5, 3.0, 1.5]\n",
    "\n",
    "# list indexing, example [:}] returns all elements and [:-1] returns all except the last one [:-1]\n",
    "x = np.linspace(0, 1, 1002)[1:-1]\n",
    "\n",
    "for i in range(0,len(a)):\n",
    "    dist = beta(a[i],b[i])\n",
    "    plt.plot(x, dist.pdf(x),label=[a[i],b[i]])\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 3)\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel(r'$p(x|\\alpha,\\beta)$')\n",
    "plt.title('Beta Distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Poisson Distribution**\n",
    "\n",
    "The Poisson Distribution is essentially the limit of the Binomial Distribution in the case where the number of trials is very large $N$ is very large (think atoms in a lump of Uranium), and the probability $\\theta$ is very small (the chances of a single atom decaying in a hour). In such a case, the Poisson Distribution is given by,\n",
    "\n",
    "$P_\\mu(\\nu) = e^{-\\mu} \\, \\dfrac{\\mu^\\nu} {\\nu!}$\n",
    "\n",
    "where $\\mu$ is the mean count rate, and $P_\\mu(\\nu)$ stands for the the probability of $\\nu$ successes (counts) in a specific interval.\n",
    "\n",
    "The standard deviation of the Poisson Distribution is given by\n",
    "$\\sigma_{\\nu} = \\sqrt{\\mu}$.\n",
    "\n",
    "This is neat result: if we measure a given number of counts $\\hat{\\nu}$ in a given interval, then the uncertainty on our count rate is simply $\\sqrt{\\hat \\nu}$.\n",
    "\n",
    "Once again, the Normal distribution can be used as an approximation to the mean, this time in the limit that $\\mu$ is large. Also note that the Poisson Distribution is *not* symmetric about the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginalisation\n",
    "\n",
    "There may exist a function $p(x, y)$ that yields the probability of both $x$ and $y$. This type of function may be a combination of discrete and continuous variables and will have units of $1/xy$. But suppose we wanted to know just $p(x)$. How do we calculate this, given that we only have $p(x, y)$? If you consider the units of the problem, the answer becomes clear: we just need to integrate or sum over $y$, i.e.\n",
    "\n",
    "$p(x) = \\int p(x, y) dy$\n",
    "\n",
    "if $y$ is a continuous variable, or\n",
    "\n",
    "$p(x) = \\sum_y p(x, y)$\n",
    "\n",
    "if $y$ is discrete. This process is called *marginalising over y*. We could do the same to get $p(y)$. Marginalisation is extremely important, since it allows us to deal with nuisance parameters, that is, those that we don't know very well (or that are not well constrained)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Weighted errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have two students, let's call them $A$ and $B$, who make a measurement of the length of our snake, $x$. Student $A$ finds the length to be $x = x_A \\pm \\sigma_A$, while student $B$ finds that $x = x_A \\pm \\sigma_A$. Given that both sets of data are valid estimates of the snake's length, we'd like to combine the results from the two experiments, to get a new, and hopefully improved result $x_{AB}$, with an associated uncertainty $\\sigma_{AB}$.\n",
    "\n",
    "How to proceed? It is tempting to simply average the two results, e.g. $x_{AB} = \\frac{x_A + x_B}{2}$, but feels a bit fishy if the two uncertainties $\\sigma_A$ and $\\sigma_B$ are not equal. Why should they have equal weighting, if one is less accurate (higher uncertainty) than the other? The answer is to weight the values according to their uncertainties, to produce a *weighted average*.\n",
    "\n",
    "To work out the maths of this, we are going to assume once again that the errors in the snake length are normally distributed, and the two experiments performed by students $A$ and $B$ were completely independent (e.g. the snake was not stretched by A during her attempt at measurement). In that case, the probability that the students would obtain their resulting lengths for the snake is given by,\n",
    "\n",
    "$P_{x_0}(x_A) \\propto \\dfrac{1}{\\sigma_A} e^{-(x_A -x_0)^2 / 2\\sigma_A}$\n",
    "for student $A$ \n",
    "\n",
    "and\n",
    "\n",
    "$P_{x_0}(x_B) \\propto \\dfrac{1}{\\sigma_B} e^{-(x_B -x_0)^2 / 2\\sigma_B}$ for student $B$. \n",
    "\n",
    "Note that the probabilities depend on the unknown, but true value of the snake's length $x_0$.\n",
    "So the probability that *both* students found the lengths $x_A$ and $x_B$ is then simply:\n",
    "\n",
    "\\begin{align}\n",
    "P_{x_0}(x_A \\cap x_B) = P_{x_0}(x_A , x_B)&= P_{x_0}(x_A) \\times P_{x_0}(x_B) \\\\\n",
    "&\\propto \\frac{1}{\\sigma_A \\sigma_B} e^{-\\chi^2/2},\n",
    "\\end{align}\n",
    "\n",
    "where we have introduced the notation $\\chi^2$ (chi-squared) as a shorthand for,\n",
    "\n",
    "$\\chi^2 = \\left( \\dfrac{x_A - x_0}{\\sigma_A} \\right)^2 + \\left( \\dfrac{x_B- x_0}{\\sigma_B} \\right)^2.$\n",
    "\n",
    "Using the principle of *maximum likelihood*, we can see that $P_{x_0}(x_A , x_B)$ has a maximum when $\\chi^2$ has a minimum. So we want to know the value of $x_0$ that would maximise the chances of $A$ finding $x_A$ *and* $B$ finding $x_B$. To do this, we need to differentiate $\\chi^2$ and set the derivative equal to zero,\n",
    "\n",
    "$2 \\dfrac{x_A - x_0}{\\sigma_A} + 2 \\dfrac{x_B- x_0}{\\sigma_B} = 0$\n",
    "\n",
    "The solution for $x_0$ is then simply,\n",
    "\n",
    "$ {\\rm best~ estimate~for~} x_0 = \\left( \\dfrac{x_A}{\\sigma_A^2} + \\dfrac{x_B}{\\sigma_B^2}  \\right) \\Big/ \\left( \\dfrac{1}{\\sigma_A^2} + \\dfrac{1}{\\sigma_B^2}  \\right)$\n",
    "\n",
    "If we define weights to have the form $w_A = \\dfrac{1}{\\sigma_A}^2$ and $w_B = \\dfrac{1}{\\sigma_B}^2$, then we can tidy this up to obtain,\n",
    "\n",
    "$\\hat{x_0} = \\dfrac{w_A x_A + w_B x_B} {w_A + w_B}$\n",
    "\n",
    "where $\\hat{x_0}$ denotes the weighted average.\n",
    "\n",
    "Using the standard error propagation formula that we covered above, we can then derive the uncertainty in $\\hat{x_0}$, as,\n",
    "\n",
    "$\\hat{\\sigma}_{x_0} = \\dfrac{1}{\\sqrt{\\sum w_i}}$\n",
    "\n",
    "where $w_i$ denotes the individual weights of each component in the average.  This type of weighting -- also called optimal weighting -- is extremely important in data analysis, and will be used later in the course, and in your CA 2!  Optimal weighting allows you to take account of all data points, with each point contributing to the final result in a way than depends on how well you trust the data (i.e. the variance of the point). The problem is, that you need to know something about the error in each point (not always the case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Your turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Question:**<br><br>\n",
    "\n",
    "Define the principle of maximum likelihood.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, this selects the parameter values that make the observed data most probable. The specific value that maximizes the likelihood function is called the maximum likelihood estimate. Further, if the function so defined is measurable, then it is called the maximum likelihood estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=warn>**Question:**<br><br>\n",
    "\n",
    "Suppose $x$ can be either 1, 2, 3 or 4, and $y$ can be either 1, 2, or 3. Write down an expression for the probability that $x=1$ ie $P(x=1)$?  Tip: this is a question about marginalisation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming there is exists a function f = p(x,y) where f: x,y -> [0,1]\n",
    "\n",
    "from above $P(X) = \\sum p(x,y)$ for y = 1,2,3\n",
    "\n",
    "$P(1) = \\sum p(1,y)$ for y = 1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">**Question:**<br><br>\n",
    "Write down the mean and standard deviation for a normal distribution and a Binomial distribution.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For normal distribution mean = $\\mu$=Np and $\\sigma^2$ = Npq where q=1-p\n",
    "\n",
    "For Binomial distribution mean = $\\mu$=np and $\\sigma^2$ = np(1-p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> **Question:**<br><br>\n",
    "The probability that a student is accepted to a prestigious university is 0.3. If 5 students from the same school apply, what is the probability that at most 2 are accepted?\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the binomial distrabution formula \n",
    "P(X=k) = (N OVER K) p^k (1-p)^n-k n=5, k=2, p=0.3\n",
    "P(X=k) = 0.3087"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">** Question:** <br><br>\n",
    "\n",
    "Three students measure the same resistance several times, with final measurements (in Ohms):\n",
    "\n",
    "Student 1: $R = 11 \\pm 1$\n",
    "Student 2: $R = 12 \\pm 1$\n",
    "Student 3: $R = 10 \\pm 3$.\n",
    "\n",
    "Given these three results what do we write down as the best estimate for the resistance $R$? Tip: you will need to use weighted errors.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the weight formula first for $\\hat{x_0}$\n",
    "\n",
    " $\\hat{x_0} = \\dfrac{w_1 x_1 + w_2 x_2 + w_3 x_3} {w_1 + w_2 + w_3}$\n",
    " $\\hat{x_0} = 10.6$\n",
    " \n",
    " $\\hat{\\sigma}_{x_0} = \\dfrac{1}{\\sqrt{\\sum w_i}}$\n",
    " \n",
    " $\\hat{\\sigma}_{x_0} = 0.688215$\n",
    " \n",
    " Resistance average = $10.6 \\pm 0.69$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=warn> **Question:** <br><br> Suppose that astronomers estimate that large meteorites (above a certain size) hit the earth on average once every 100 years, and that the number of meteorite hits follows a Poisson distribution. What is the probability of zero meteorite hits in the next 100 years?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(X,\\mu) = \\dfrac{(e^{-\\mu})(\\mu^x)}{x!}$\n",
    "\n",
    "$\\mu = 1$ since 1 hits per 100 years\n",
    "$x = 0$ as we dont want any colissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=warn>**Question:**<br><br>\n",
    "    \n",
    "Astronomers take an image of the galaxy M42 with a telescope to measure its brightness. But they find that the image has background light across the whole picture (we call this a positive background level) which affects the measured brightness of the galaxy. They want to subtract this level off the image.   They don't know whether the mean background value in the image or the median background value is a better estimate of the background. <br><br>\n",
    "\n",
    "Take the image and plot a histogram of the brightness measured across the image. Overplot the mean and median values and decide which one provides the best measurement of the nuisance background light.<br><br>\n",
    "\n",
    "Tip:  import the following `import matplotlib.pyplot as plt` and `from astropy.io import fits` and read in the image file of the galaxy using the following commands<br><br>\n",
    "\n",
    "`image_data = fits.getdata('galaxym42.fits.fz')` <br><br>\n",
    "\n",
    "`histogram = plt.hist(image_data.flatten(),1000,histtype='bar')`\n",
    "\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "\n",
    "image_data = fits.getdata('/home/cot12/Downloads/galaxym42.fits.fz')\n",
    "histogram = plt.hist(image_data.flatten(),1000,histtype='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=warn> **Question** <br><br>\n",
    "\n",
    "Prove, using the principle of maximum likelihood that the mean is the best estimate for $x$ given $N$ measurements, if $x$ follows a normal distribution with unknown parameters $x_0$ and $\\sigma$.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your Answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
